{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "572668f3",
   "metadata": {},
   "source": [
    "# Name: Neelanjan Dutta"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93ac05be",
   "metadata": {},
   "source": [
    "# Register number: 2448040"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a8e0696",
   "metadata": {},
   "source": [
    "# Program #1: Implementing a Simple Perceptron for Real-Time Binary Classification."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72008bd3",
   "metadata": {},
   "source": [
    "### (a)Select a real-time scenario where a binary classification is applicable. Some examples include(Classifying emails as spam or not spam,Predicting whether a patient has diabetes or not,Identifying if a customer will churn or stay,Classifying whether a stock market trend is up or down,Classifying a person as employed or unemployed)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "656c4b63",
   "metadata": {},
   "source": [
    "### Answer:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9db10c20",
   "metadata": {},
   "source": [
    "<b> Selected Scenario: </b>\n",
    "Classifying whether a patient has heart disease based on clinical and physiological features.<br>\n",
    "This is a real-world binary classification task where: <br>\n",
    "(i) <b>Presence (1)</b> means the patient is diagnosed with heart disease. <br>\n",
    "(ii) <b>Absence (0)</b> means the patient does not have heart disease.<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bd4299e",
   "metadata": {},
   "source": [
    "### (b)Choose a dataset relevant to your scenario. You may Use publicly available datasets (e.g., UCI Machine Learning Repository, Kaggle.Generate a simple synthetic dataset if needed."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ec9442a",
   "metadata": {},
   "source": [
    "### Answer:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afde4cab",
   "metadata": {},
   "source": [
    "<b>Selected Dataset:</b> <br>\n",
    "\n",
    "Heart Disease UCI Dataset<br>\n",
    "<br>\n",
    "<b>Dataset Source:</b> <br>\n",
    "\n",
    "Available from the UCI Machine Learning Repository<br>\n",
    "\n",
    "Preprocessed and commonly used version available on Kaggle<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9716529",
   "metadata": {},
   "source": [
    "### c) Implement the Perceptron algorithm from scratch,including:Initialization of weights and bias,Weight update rule using gradient descent,Activation function (step function or threshold function),Training loop based on epochs."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3865425",
   "metadata": {},
   "source": [
    "### Answer:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4f5c8dd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Load the dataset \n",
    "df = pd.read_csv(\"C:/Users/Neelanjan Dutta/Downloads/heart.csv\")\n",
    "\n",
    "# Features and target\n",
    "X = df.drop('target', axis=1)  # 13 features\n",
    "y = df['target']               # 1 = Heart disease, 0 = No disease\n",
    "\n",
    "# Standardize the features\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "# Split the dataset into training and testing sets (80-20 split)\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X_scaled, y, test_size=0.2, random_state=42\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d47d8c70",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Total Errors: 156, Training Accuracy: 0.7585\n",
      "Epoch 2, Total Errors: 164, Training Accuracy: 0.7561\n",
      "Epoch 3, Total Errors: 169, Training Accuracy: 0.7476\n",
      "Epoch 4, Total Errors: 163, Training Accuracy: 0.7524\n",
      "Epoch 5, Total Errors: 152, Training Accuracy: 0.7573\n",
      "Epoch 6, Total Errors: 157, Training Accuracy: 0.7805\n",
      "Epoch 7, Total Errors: 164, Training Accuracy: 0.7780\n",
      "Epoch 8, Total Errors: 170, Training Accuracy: 0.7671\n",
      "Epoch 9, Total Errors: 159, Training Accuracy: 0.7720\n",
      "Epoch 10, Total Errors: 164, Training Accuracy: 0.7768\n",
      "Epoch 11, Total Errors: 154, Training Accuracy: 0.7427\n",
      "Stopping early. Accuracy did not improve for 5 consecutive epochs.\n",
      "\n",
      "Test Accuracy: 0.6927\n"
     ]
    }
   ],
   "source": [
    "# Define Perceptron Model from Scratch\n",
    "class Perceptron:\n",
    "    def __init__(self, input_dim, lr=0.01, epochs=100):\n",
    "        self.lr = lr\n",
    "        self.epochs = epochs\n",
    "        self.weights = np.zeros(input_dim)\n",
    "        self.bias = 0\n",
    "\n",
    "    def activation(self, x):\n",
    "        # Step/Threshold Activation Function\n",
    "        return 1 if x >= 0 else 0\n",
    "\n",
    "    def predict(self, x):\n",
    "        z = np.dot(x, self.weights) + self.bias\n",
    "        return self.activation(z)\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        best_accuracy = 0\n",
    "        patience = 5     # Number of epochs to wait if no improvement\n",
    "        wait = 0\n",
    "        accuracy_list = []\n",
    "\n",
    "        for epoch in range(self.epochs):\n",
    "            total_error = 0\n",
    "            for xi, target in zip(X, y):\n",
    "                z = np.dot(xi, self.weights) + self.bias\n",
    "                y_pred = self.activation(z)\n",
    "                error = target - y_pred\n",
    "\n",
    "                # Weight update rule using gradient descent\n",
    "                self.weights += self.lr * error * xi\n",
    "                self.bias += self.lr * error\n",
    "                total_error += abs(error)\n",
    "\n",
    "            # Calculate training accuracy\n",
    "            predictions = [self.predict(xi) for xi in X]\n",
    "            accuracy = np.mean(predictions == y)\n",
    "            accuracy_list.append(accuracy)\n",
    "\n",
    "            print(f\"Epoch {epoch+1}, Total Errors: {total_error}, Training Accuracy: {accuracy:.4f}\")\n",
    "\n",
    "            # Smart Early Stopping: stop if accuracy doesn't improve\n",
    "            if accuracy > best_accuracy:\n",
    "                best_accuracy = accuracy\n",
    "                wait = 0\n",
    "            else:\n",
    "                wait += 1\n",
    "                if wait >= patience:\n",
    "                    print(f\"Stopping early. Accuracy did not improve for {patience} consecutive epochs.\")\n",
    "                    break\n",
    "\n",
    "# Create the model and train\n",
    "model = Perceptron(input_dim=X_train.shape[1], lr=0.01, epochs=100)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Evaluate on test data\n",
    "y_pred = [model.predict(x) for x in X_test]\n",
    "test_accuracy = np.mean(y_pred == y_test)\n",
    "print(f\"\\nTest Accuracy: {test_accuracy:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "102f0325",
   "metadata": {},
   "source": [
    "A Perceptron model is implemented from scratch using Python and NumPy.<br>\n",
    "<br>\n",
    "Weights and bias are initialized to zero.<br>\n",
    "<br>\n",
    "A step (threshold) activation function is used: outputs 1 if the input ≥ 0, else 0. <br>\n",
    "<br>\n",
    "For each training sample, the model computes the weighted sum and applies the activation function to make a prediction.<br>\n",
    "<br>\n",
    "The prediction is compared to the actual label, and the weights and bias are updated using the Perceptron learning rule based on the prediction error.<br>\n",
    "<br>\n",
    "Total error per epoch is tracked to monitor convergence, and training accuracy is computed after each epoch.<br>\n",
    "<br>\n",
    "Early stopping is applied: training halts if the accuracy does not improve for 5 consecutive epochs.<br>\n",
    "<br>\n",
    "Finally, the trained model is evaluated on unseen test data, and the test accuracy is reported.<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83674b9b",
   "metadata": {},
   "source": [
    "# Program #2: Implementing an ADALINE Neural Network for AND Logic Gate and Real-Time Binary Classification."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7879db95",
   "metadata": {},
   "source": [
    "### a)Implement the ADALINE model using Python with the following features:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "482f17af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1\n",
      "Input: [1 1], Target: 1, Output: 0.00, Error: 1.00, Weights: [0.1 0.1], Bias: 0.100\n",
      "Input: [ 1 -1], Target: -1, Output: 0.10, Error: -1.10, Weights: [-0.01  0.21], Bias: -0.010\n",
      "Input: [-1  1], Target: -1, Output: 0.21, Error: -1.21, Weights: [0.111 0.089], Bias: -0.131\n",
      "Input: [-1 -1], Target: -1, Output: -0.33, Error: -0.67, Weights: [0.178 0.156], Bias: -0.198\n",
      "MSE = 1.0304, Outputs = [ 0.14 -0.18 -0.22 -0.53], Predictions = [ 1. -1. -1. -1.]\n",
      "\n",
      "Epoch 2\n",
      "Input: [1 1], Target: 1, Output: 0.14, Error: 0.86, Weights: [0.264 0.242], Bias: -0.111\n",
      "Input: [ 1 -1], Target: -1, Output: -0.09, Error: -0.91, Weights: [0.173 0.333], Bias: -0.203\n",
      "Input: [-1  1], Target: -1, Output: -0.04, Error: -0.96, Weights: [0.269 0.238], Bias: -0.298\n",
      "Input: [-1 -1], Target: -1, Output: -0.80, Error: -0.20, Weights: [0.289 0.257], Bias: -0.318\n",
      "MSE = 0.6327, Outputs = [ 0.23 -0.29 -0.35 -0.86], Predictions = [ 1. -1. -1. -1.]\n",
      "\n",
      "Epoch 3\n",
      "Input: [1 1], Target: 1, Output: 0.23, Error: 0.77, Weights: [0.366 0.334], Bias: -0.241\n",
      "Input: [ 1 -1], Target: -1, Output: -0.21, Error: -0.79, Weights: [0.287 0.413], Bias: -0.320\n",
      "Input: [-1  1], Target: -1, Output: -0.19, Error: -0.81, Weights: [0.367 0.333], Bias: -0.400\n",
      "Input: [-1 -1], Target: -1, Output: -1.10, Error: 0.10, Weights: [0.357 0.323], Bias: -0.390\n",
      "MSE = 0.4708, Outputs = [ 0.29 -0.36 -0.42 -1.07], Predictions = [ 1. -1. -1. -1.]\n",
      "\n",
      "Epoch 4\n",
      "Input: [1 1], Target: 1, Output: 0.29, Error: 0.71, Weights: [0.428 0.394], Bias: -0.319\n",
      "Input: [ 1 -1], Target: -1, Output: -0.28, Error: -0.72, Weights: [0.357 0.465], Bias: -0.391\n",
      "Input: [-1  1], Target: -1, Output: -0.28, Error: -0.72, Weights: [0.429 0.393], Bias: -0.463\n",
      "Input: [-1 -1], Target: -1, Output: -1.28, Error: 0.28, Weights: [0.4   0.365], Bias: -0.434\n",
      "MSE = 0.4031, Outputs = [ 0.33 -0.4  -0.47 -1.2 ], Predictions = [ 1. -1. -1. -1.]\n",
      "\n",
      "Epoch 5\n",
      "Input: [1 1], Target: 1, Output: 0.33, Error: 0.67, Weights: [0.467 0.432], Bias: -0.367\n",
      "Input: [ 1 -1], Target: -1, Output: -0.33, Error: -0.67, Weights: [0.4   0.499], Bias: -0.434\n",
      "Input: [-1  1], Target: -1, Output: -0.34, Error: -0.66, Weights: [0.467 0.432], Bias: -0.500\n",
      "Input: [-1 -1], Target: -1, Output: -1.40, Error: 0.40, Weights: [0.427 0.392], Bias: -0.461\n",
      "MSE = 0.3737, Outputs = [ 0.36 -0.43 -0.49 -1.28], Predictions = [ 1. -1. -1. -1.]\n",
      "\n",
      "Epoch 6\n",
      "Input: [1 1], Target: 1, Output: 0.36, Error: 0.64, Weights: [0.491 0.456], Bias: -0.396\n",
      "Input: [ 1 -1], Target: -1, Output: -0.36, Error: -0.64, Weights: [0.427 0.52 ], Bias: -0.460\n",
      "Input: [-1  1], Target: -1, Output: -0.37, Error: -0.63, Weights: [0.49  0.457], Bias: -0.523\n",
      "Input: [-1 -1], Target: -1, Output: -1.47, Error: 0.47, Weights: [0.443 0.41 ], Bias: -0.476\n",
      "MSE = 0.3602, Outputs = [ 0.38 -0.44 -0.51 -1.33], Predictions = [ 1. -1. -1. -1.]\n",
      "\n",
      "Epoch 7\n",
      "Input: [1 1], Target: 1, Output: 0.38, Error: 0.62, Weights: [0.506 0.472], Bias: -0.414\n",
      "Input: [ 1 -1], Target: -1, Output: -0.38, Error: -0.62, Weights: [0.444 0.534], Bias: -0.476\n",
      "Input: [-1  1], Target: -1, Output: -0.39, Error: -0.61, Weights: [0.505 0.473], Bias: -0.537\n",
      "Input: [-1 -1], Target: -1, Output: -1.52, Error: 0.52, Weights: [0.454 0.421], Bias: -0.486\n",
      "MSE = 0.3538, Outputs = [ 0.39 -0.45 -0.52 -1.36], Predictions = [ 1. -1. -1. -1.]\n",
      "\n",
      "Epoch 8\n",
      "Input: [1 1], Target: 1, Output: 0.39, Error: 0.61, Weights: [0.515 0.482], Bias: -0.425\n",
      "Input: [ 1 -1], Target: -1, Output: -0.39, Error: -0.61, Weights: [0.454 0.543], Bias: -0.486\n",
      "Input: [-1  1], Target: -1, Output: -0.40, Error: -0.60, Weights: [0.514 0.483], Bias: -0.546\n",
      "Input: [-1 -1], Target: -1, Output: -1.54, Error: 0.54, Weights: [0.46  0.428], Bias: -0.492\n",
      "MSE = 0.3504, Outputs = [ 0.4  -0.46 -0.52 -1.38], Predictions = [ 1. -1. -1. -1.]\n",
      "\n",
      "Epoch 9\n",
      "Input: [1 1], Target: 1, Output: 0.40, Error: 0.60, Weights: [0.52  0.489], Bias: -0.431\n",
      "Input: [ 1 -1], Target: -1, Output: -0.40, Error: -0.60, Weights: [0.46  0.549], Bias: -0.491\n",
      "Input: [-1  1], Target: -1, Output: -0.40, Error: -0.60, Weights: [0.52  0.489], Bias: -0.551\n",
      "Input: [-1 -1], Target: -1, Output: -1.56, Error: 0.56, Weights: [0.464 0.433], Bias: -0.495\n",
      "MSE = 0.3486, Outputs = [ 0.4  -0.46 -0.53 -1.39], Predictions = [ 1. -1. -1. -1.]\n",
      "\n",
      "Epoch 10\n",
      "Input: [1 1], Target: 1, Output: 0.40, Error: 0.60, Weights: [0.524 0.493], Bias: -0.435\n",
      "Input: [ 1 -1], Target: -1, Output: -0.40, Error: -0.60, Weights: [0.464 0.552], Bias: -0.495\n",
      "Input: [-1  1], Target: -1, Output: -0.41, Error: -0.59, Weights: [0.524 0.493], Bias: -0.554\n",
      "Input: [-1 -1], Target: -1, Output: -1.57, Error: 0.57, Weights: [0.466 0.436], Bias: -0.497\n",
      "MSE = 0.3476, Outputs = [ 0.41 -0.47 -0.53 -1.4 ], Predictions = [ 1. -1. -1. -1.]\n",
      "\n",
      "Epoch 11\n",
      "Input: [1 1], Target: 1, Output: 0.41, Error: 0.59, Weights: [0.526 0.495], Bias: -0.438\n",
      "Input: [ 1 -1], Target: -1, Output: -0.41, Error: -0.59, Weights: [0.467 0.555], Bias: -0.497\n",
      "Input: [-1  1], Target: -1, Output: -0.41, Error: -0.59, Weights: [0.526 0.496], Bias: -0.556\n",
      "Input: [-1 -1], Target: -1, Output: -1.58, Error: 0.58, Weights: [0.468 0.438], Bias: -0.498\n",
      "MSE = 0.3470, Outputs = [ 0.41 -0.47 -0.53 -1.4 ], Predictions = [ 1. -1. -1. -1.]\n",
      "\n",
      "Epoch 12\n",
      "Input: [1 1], Target: 1, Output: 0.41, Error: 0.59, Weights: [0.527 0.497], Bias: -0.439\n",
      "Input: [ 1 -1], Target: -1, Output: -0.41, Error: -0.59, Weights: [0.468 0.556], Bias: -0.498\n",
      "Input: [-1  1], Target: -1, Output: -0.41, Error: -0.59, Weights: [0.527 0.497], Bias: -0.557\n",
      "Input: [-1 -1], Target: -1, Output: -1.58, Error: 0.58, Weights: [0.469 0.439], Bias: -0.499\n",
      "MSE = 0.3466, Outputs = [ 0.41 -0.47 -0.53 -1.41], Predictions = [ 1. -1. -1. -1.]\n",
      "\n",
      "Epoch 13\n",
      "Input: [1 1], Target: 1, Output: 0.41, Error: 0.59, Weights: [0.528 0.498], Bias: -0.440\n",
      "Input: [ 1 -1], Target: -1, Output: -0.41, Error: -0.59, Weights: [0.469 0.557], Bias: -0.499\n",
      "Input: [-1  1], Target: -1, Output: -0.41, Error: -0.59, Weights: [0.528 0.498], Bias: -0.558\n",
      "Input: [-1 -1], Target: -1, Output: -1.58, Error: 0.58, Weights: [0.47 0.44], Bias: -0.499\n",
      "MSE = 0.3464, Outputs = [ 0.41 -0.47 -0.53 -1.41], Predictions = [ 1. -1. -1. -1.]\n",
      "\n",
      "Epoch 14\n",
      "Input: [1 1], Target: 1, Output: 0.41, Error: 0.59, Weights: [0.529 0.499], Bias: -0.440\n",
      "Input: [ 1 -1], Target: -1, Output: -0.41, Error: -0.59, Weights: [0.47  0.558], Bias: -0.499\n",
      "Input: [-1  1], Target: -1, Output: -0.41, Error: -0.59, Weights: [0.529 0.499], Bias: -0.558\n",
      "Input: [-1 -1], Target: -1, Output: -1.59, Error: 0.59, Weights: [0.47 0.44], Bias: -0.500\n",
      "MSE = 0.3463, Outputs = [ 0.41 -0.47 -0.53 -1.41], Predictions = [ 1. -1. -1. -1.]\n",
      "\n",
      "Epoch 15\n",
      "Input: [1 1], Target: 1, Output: 0.41, Error: 0.59, Weights: [0.529 0.499], Bias: -0.441\n",
      "Input: [ 1 -1], Target: -1, Output: -0.41, Error: -0.59, Weights: [0.47  0.558], Bias: -0.500\n",
      "Input: [-1  1], Target: -1, Output: -0.41, Error: -0.59, Weights: [0.529 0.499], Bias: -0.558\n",
      "Input: [-1 -1], Target: -1, Output: -1.59, Error: 0.59, Weights: [0.47  0.441], Bias: -0.500\n",
      "MSE = 0.3462, Outputs = [ 0.41 -0.47 -0.53 -1.41], Predictions = [ 1. -1. -1. -1.]\n",
      "\n",
      "Stopped at epoch 15: MSE no longer improving significantly (Δ=0.000088).\n",
      "\n",
      "Final Weights: [0.47020416 0.44064375]\n",
      "Final Bias: -0.4998035420747783\n",
      "Final Outputs: [ 0.41 -0.47 -0.53 -1.41]\n",
      "Final Predictions: [ 1. -1. -1. -1.]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Bipolar AND gate\n",
    "X = np.array([[1, 1], [1, -1], [-1, 1], [-1, -1]])\n",
    "T = np.array([1, -1, -1, -1])\n",
    "\n",
    "# Initialization\n",
    "w = np.zeros(2)\n",
    "b = 0.0\n",
    "alpha = 0.1\n",
    "max_epochs = 100\n",
    "mse_tolerance = 0.0001  # how small an improvement we expect\n",
    "prev_mse = float('inf')\n",
    "\n",
    "for epoch in range(max_epochs):\n",
    "    print(f\"\\nEpoch {epoch + 1}\")\n",
    "    total_error = 0\n",
    "\n",
    "    for i in range(len(X)):\n",
    "        x = X[i]\n",
    "        t = T[i]\n",
    "\n",
    "        y = np.dot(w, x) + b\n",
    "        error = t - y\n",
    "\n",
    "        # Update weights and bias\n",
    "        w += alpha * error * x\n",
    "        b += alpha * error\n",
    "        total_error += error ** 2\n",
    "\n",
    "        print(f\"Input: {x}, Target: {t}, Output: {y:.2f}, Error: {error:.2f}, Weights: {np.round(w, 3)}, Bias: {b:.3f}\")\n",
    "\n",
    "    # After epoch: compute overall predictions and MSE\n",
    "    outputs = np.dot(X, w) + b\n",
    "    predictions = np.sign(outputs)\n",
    "    mse = total_error / len(X)\n",
    "\n",
    "    print(f\"MSE = {mse:.4f}, Outputs = {np.round(outputs, 2)}, Predictions = {predictions}\")\n",
    "\n",
    "    if not np.array_equal(predictions, T):\n",
    "        print(f\"\\nStopped at epoch {epoch + 1}: Predictions no longer match targets.\")\n",
    "        break\n",
    "\n",
    "    if prev_mse - mse < mse_tolerance:\n",
    "        print(f\"\\nStopped at epoch {epoch + 1}: MSE no longer improving significantly (Δ={prev_mse - mse:.6f}).\")\n",
    "        break\n",
    "\n",
    "    prev_mse = mse\n",
    "\n",
    "# Final results\n",
    "print(\"\\nFinal Weights:\", w)\n",
    "print(\"Final Bias:\", b)\n",
    "print(\"Final Outputs:\", np.round(outputs, 2))\n",
    "print(\"Final Predictions:\", predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e77c512",
   "metadata": {},
   "source": [
    "- This program implements the ADALINE (Adaptive Linear Neuron) model for a bipolar AND logic gate. <br>\n",
    "- Inputs and targets are given in bipolar format, Inputs: [1, 1], [1, -1], [-1, 1], [-1, -1] Targets: [1, -1, -1, -1]<br>\n",
    "- Initial weights and bias are set to zero. A linear output (raw net input) is used during learning instead of a threshold.<br>\n",
    "- The original learning rate (α = 1) was reduced to α = 0.1 for the following reason:<br>\n",
    "<br>\n",
    "ADALINE uses raw (continuous) outputs to minimize Mean Squared Error (MSE).<br>\n",
    "A high learning rate like α = 1 causes large weight updates, leading to unstable learning and exploding error.<br>\n",
    "Reducing the learning rate to 0.1 ensures gradual, stable convergence of the model.<br>\n",
    "<br>\n",
    "<b>For each epoch:</b><br>\n",
    "The model computes output y = w·x + b . Calculates error t − y <br>\n",
    "Updates weights and bias using the delta rule (gradient descent). The model monitors Mean Squared Error (MSE) after every epoch.<br>\n",
    "<br>\n",
    "<b>Training stops early if:</b><br>\n",
    "- All predictions match the target values (perfect learning), or <br>\n",
    "- Change in MSE is very small (< 0.0001), indicating convergence<br>\n",
    "<br>\n",
    "Final learned weights, bias, outputs, and predictions are printed.<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76667d56",
   "metadata": {},
   "source": [
    "### b)Real-Time Binary Classification with ADALINE:Choose a real-world binary classification scenario (ex.)Predict if a patient has diabetes (Yes/No),Predict customer churn (Churn/No Churn) etc.Select or load an appropriate dataset,Train an ADALINE model on the data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4724bd1",
   "metadata": {},
   "source": [
    "### Answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5a4aef99",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Load the Heart Disease dataset\n",
    "df = pd.read_csv(\"C:/Users/Neelanjan Dutta/Downloads/heart.csv\")\n",
    "\n",
    "X = df[['age', 'trestbps', 'chol']] \n",
    "\n",
    "# Target: 1 = heart disease, 0 = no disease\n",
    "y = df['target']\n",
    "\n",
    "# Convert labels to bipolar format: 0 → -1, 1 → +1\n",
    "y = np.where(y == 0, -1, 1)\n",
    "\n",
    "# Standardize features (important for ADALINE convergence)\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "# Train-test split \n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X_scaled, y, test_size=0.2, random_state=42\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c87d6b9e",
   "metadata": {},
   "source": [
    "<b>Dataset Used:</b> The Heart Disease Dataset (commonly from UCI or Kaggle) is used for binary classification of patients: (0 → No Disease, 1 → Presence of Disease) <br>\n",
    "<b>Classification Task:</b> The goal is to train an ADALINE model to classify whether a person has heart disease or not, based on clinical measurements.<br>\n",
    "<b>Feature Selection (Only 3 Features):</b> We selected only 3 numerical features: age, resting blood pressure (trestbps), and cholesterol (chol).<br>\n",
    "<br>\n",
    "This is done to:<br>\n",
    "Keep the model simple and interpretable<br>\n",
    "Reduce computational complexity and help visualize weight updates<br>\n",
    "Ensure better stability for ADALINE, which is sensitive to dimensionality<br>\n",
    "These 3 features are also known to be medically relevant in predicting heart disease.<br>\n",
    "<br>\n",
    "Target Conversion to Bipolar Form:<br>\n",
    "ADALINE works with bipolar outputs. So, the binary targets are converted as:<br>\n",
    "(0 → -1 (no heart disease) 1 → +1 (presence of heart disease))<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4ac51d47",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 | MSE: 0.9616 | Accuracy: 0.6427\n",
      "Epoch 2 | MSE: 0.9615 | Accuracy: 0.6427\n",
      "\n",
      "Stopped early at epoch 2: MSE stabilized (Δ=0.000065)\n",
      "\n",
      "Final Test Accuracy: 0.6000\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Define ADALINE Model\n",
    "class ADALINE:\n",
    "    def __init__(self, input_dim, lr=0.01, epochs=100):\n",
    "        self.lr = lr\n",
    "        self.epochs = epochs\n",
    "        self.weights = np.zeros(input_dim)\n",
    "        self.bias = 0.0  # Ensure float\n",
    "\n",
    "    def net_input(self, x):\n",
    "        return np.dot(x, self.weights) + self.bias\n",
    "\n",
    "    def activation(self, x):\n",
    "        return x  # Linear activation\n",
    "\n",
    "    def predict(self, X):\n",
    "        output = self.net_input(X)\n",
    "        return np.where(output >= 0, 1, -1)\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        prev_mse = float('inf')\n",
    "        mse_tolerance = 0.0001\n",
    "\n",
    "        for epoch in range(self.epochs):\n",
    "            total_error = 0\n",
    "            for xi, target in zip(X, y):\n",
    "                output = self.net_input(xi)\n",
    "                error = target - output\n",
    "\n",
    "                # ADALINE weight update rule\n",
    "                self.weights += self.lr * error * xi\n",
    "                self.bias += self.lr * error\n",
    "\n",
    "                total_error += error ** 2\n",
    "\n",
    "            mse = total_error / len(X)\n",
    "            predictions = self.predict(X)\n",
    "            accuracy = np.mean(predictions == y)\n",
    "\n",
    "            print(f\"Epoch {epoch+1} | MSE: {mse:.4f} | Accuracy: {accuracy:.4f}\")\n",
    "\n",
    "            # Early Stopping\n",
    "            if np.array_equal(predictions, y):\n",
    "                print(f\"\\nStopped early at epoch {epoch+1}: Perfect classification on training set.\")\n",
    "                break\n",
    "            if abs(prev_mse - mse) < mse_tolerance:\n",
    "                print(f\"\\nStopped early at epoch {epoch+1}: MSE stabilized (Δ={abs(prev_mse - mse):.6f})\")\n",
    "                break\n",
    "\n",
    "            prev_mse = mse\n",
    "\n",
    "# Train the model on Heart Disease dataset\n",
    "model = ADALINE(input_dim=X_train.shape[1], lr=0.01, epochs=100)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Evaluate on test data\n",
    "y_pred = model.predict(X_test)\n",
    "test_accuracy = np.mean(y_pred == y_test)\n",
    "print(f\"\\nFinal Test Accuracy: {test_accuracy:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "091e6257",
   "metadata": {},
   "source": [
    "<b>Model Used:</b> An ADALINE (Adaptive Linear Neuron) model is defined and trained from scratch.<br>\n",
    "Training Method: The model uses:<br>\n",
    "Linear activation (output = w·x + b) during training<br>\n",
    "Sign function (+1 / -1) for binary prediction<br>\n",
    "<b>Learning Rate:</b><br>\n",
    "lr = 0.01 is chosen to ensure stable and gradual learning via gradient descent.<br>\n",
    "<b>Loss Function:</b><br>\n",
    "The model minimizes Mean Squared Error (MSE) between predicted continuous outputs and target labels.<br>\n",
    "<b>Weight Updates:</b><br>\n",
    "Weights and bias are updated after each training sample using the delta learning rule:<br>\n",
    "<center>w = w + α⋅(target − output)⋅x</center> <br>\n",
    "<center>b = b + α⋅(target − output)</center><br>\n",
    "<b>Stopping Criteria Used:</b><br>\n",
    "If MSE stops improving significantly (Δ < 0.0001)<br>\n",
    "If all training predictions match the targets perfectly<br>\n",
    "<b>Output Observation:</b>\n",
    "Epoch 1 | MSE: 0.9616 | Accuracy: 0.6427<br>\n",
    "Epoch 2 | MSE: 0.9615 | Accuracy: 0.6427<br>\n",
    "Stopped early at epoch 2: MSE stabilized (Δ=0.000065)<br>\n",
    "Final test accuracy on unseen data was 60.00%  <br>\n",
    "<br>\n",
    "<b>Interpretation:</b><br>\n",
    "The ADALINE model converged quickly due to standardized features and a conservative learning rate.<br>\n",
    "However, test accuracy was limited (60%) because the Heart Disease dataset is not linearly separable, and ADALINE is a linear model.<br>\n",
    "Using only 3 features (age, trestbps, chol) further restricts the model’s ability to capture complex decision boundaries.<br>\n",
    "Despite lower accuracy, the model training behaved as expected, demonstrating stable convergence and early stopping.<br>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
